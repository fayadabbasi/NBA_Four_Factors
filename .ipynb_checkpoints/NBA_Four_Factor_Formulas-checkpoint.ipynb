{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scrape(inputlist):    \n",
    "    ''' \n",
    "    create a total boxscore scrape of each game. \n",
    "    \n",
    "    INPUT: use the pickle function to get the unique website identifier\n",
    "    \n",
    "    OUTPUT: return a pandas dataframe with all player and team statistics. \n",
    "    '''\n",
    "    \n",
    "    year = inputlist[:4]\n",
    "    month = inputlist[4:6]\n",
    "    day = inputlist[6:8]\n",
    "    team = inputlist[9:] \n",
    "    # from the pickle, had to modify the inputlist single string to its components\n",
    "    \n",
    "    web_template = (f'https://www.basketball-reference.com/boxscores/{year}{month}{day}0{team}.html')\n",
    "    data = requests.get(web_template)\n",
    "    soup = BeautifulSoup(data.text, 'html.parser')\n",
    "    # scrape the site\n",
    "    \n",
    "    \n",
    "    headers_four_factors = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]\n",
    "    rows = soup.findAll('tr')[2:]\n",
    "    player_stats1 = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
    "    player_names1 = [[td.getText() for td in rows[i].findAll('th')] for i in range(len(rows))]\n",
    "    # run some list comprehensions to identify the headers for the table, the player statistics and separately \n",
    "    # the player name since that is not included in player statistics\n",
    "    \n",
    "    stats = pd.DataFrame(player_stats1, columns = headers_four_factors[1:])\n",
    "    player = pd.DataFrame(player_names1)\n",
    "    player = player[0][:66]\n",
    "    stats['Player'] = player\n",
    "    # create a statistics dataframe and a player name dataframe and then append the player name to the stats\n",
    "    # return the assembled dataframe\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_summary(inputlist):    \n",
    "    '''\n",
    "    create a summary table with team name and team score\n",
    "    \n",
    "    INPUT: use the pickle function to get the unique website identifier\n",
    "    \n",
    "    OUTPUT: return a pandas dataframe with a summary box score for the team\n",
    "    '''\n",
    "    \n",
    "    year = inputlist[:4]\n",
    "    month = inputlist[4:6]\n",
    "    day = inputlist[6:8]\n",
    "    team = inputlist[9:]\n",
    "    # from the pickle, had to modify the inputlist single string to its components\n",
    "    \n",
    "    \n",
    "    web_template = (f'https://www.basketball-reference.com/boxscores/{year}{month}{day}0{team}.html')\n",
    "    data = requests.get(web_template)\n",
    "    soup = BeautifulSoup(data.text, 'html.parser')\n",
    "    # perform the web scrape\n",
    "    \n",
    "    rows2 = soup.findAll(class_='scorebox')\n",
    "    overall_teams = [strong.getText() for strong in rows2[0].findAll('strong')]\n",
    "    overall_teams = [items.strip('\\n') for items in overall_teams]\n",
    "    overall_score = [scores.getText() for scores in rows2[0].findAll(class_='scores')]\n",
    "    overall_score = [items.strip('\\n') for items in overall_score]\n",
    "    # parse the scrape and perform two lsit comprehensions to identify team name and team scores. \n",
    "    # also, filter out the \\n\n",
    "    \n",
    "    \n",
    "    def date_adjustment():\n",
    "        # create a sub function to scrape a different portion of the site for information about the date of the game\n",
    "        overall_date = [dates.getText() for dates in rows2[0].findAll(class_='scorebox_meta')]\n",
    "        overall_date = [items.strip('\\n') for items in overall_date]\n",
    "        overall_date_2 = [items.split(',') for items in overall_date]\n",
    "        \n",
    "        output_list = []\n",
    "        output_list.append(overall_date_2[0][0])\n",
    "        output_list.append(overall_date_2[0][1])\n",
    "        output_list.append(overall_date_2[0][2][:5].strip(' '))\n",
    "        # append three parts of the date: the time, the date, and the year\n",
    "        # the output is a list of the three components\n",
    "        \n",
    "        return output_list\n",
    "    \n",
    "    \n",
    "    date_list = [' '.join(date_adjustment())] * 2\n",
    "    # create a list with two entries of the date_adjustment function for each team\n",
    "    \n",
    "    teams_scores = pd.DataFrame(overall_teams, columns=['Team_Name'])\n",
    "    teams_scores['Score'] = overall_score\n",
    "    teams_scores['Date'] = date_list\n",
    "    # assemble the final dataframe from the three separate lists: scores, team names, and date\n",
    "    \n",
    "    return teams_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_factors_output(inputlist):\n",
    "    '''\n",
    "    Using the information from the web_scrape and team_summary dataframes, create a final dataframe\n",
    "    with the relevant data for analysis. \n",
    "    \n",
    "    INPUT: use the pickle function to get the unique website identifier\n",
    "    \n",
    "    OUTPUT: return a pandas dataframe with the information I am looking for to perform my statistical analysis. \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    year = inputlist[:4]\n",
    "    month = inputlist[4:6]\n",
    "    day = inputlist[6:8]\n",
    "    team = inputlist[9:]\n",
    "    # from the pickle, had to modify the inputlist single string to its components\n",
    "    \n",
    "    stats = web_scrape(inputlist)\n",
    "    teams_scores = team_summary(inputlist)\n",
    "    # input information from the web_scrape and team_summary functions\n",
    "    \n",
    "    test = stats[['Player','MP','FG', 'FGA', '3P', 'FT', 'ORB', 'TOV', 'FTA', 'DRB', 'PTS']]    \n",
    "    test_list = ['FG', 'FGA', '3P', 'FT', 'ORB', 'TOV', 'FTA', 'DRB']\n",
    "    test = test.dropna()\n",
    "    for items in test_list:\n",
    "        test[items] = pd.to_numeric(test[items], errors='coerce').fillna(0).astype(int)\n",
    "    # drop all rows from the dataframe that had null values - this left me with a dataset that only\n",
    "    # contained the rows of data I was interested in analyzing. Then convert all components to numerics\n",
    "    # so that I can perform math functions on those columns. \n",
    "    \n",
    "    \n",
    "    test['Player'][test['PTS']==teams_scores['Score'].iloc[0]] = teams_scores['Team_Name'].iloc[0]\n",
    "    test['Player'][test['PTS']==teams_scores['Score'].iloc[1]] = teams_scores['Team_Name'].iloc[1]\n",
    "    test['Date'] = teams_scores['Date'].iloc[0]\n",
    "    # rename the teams to match the point totals from the summary table. Also add in date. \n",
    "    \n",
    "    \n",
    "    test['eFG'] = (test['FG'] + 0.5* test['3P']) / test['FGA']\n",
    "    test['TOV_per'] = test['TOV'] / (test['FGA'] + 0.44 * test['FTA'] + test['TOV'])\n",
    "    test['ORB_per'] = test['ORB'] / (test['ORB'] + test['DRB'])\n",
    "    test['FTr'] = test['FT'] / test['FGA']\n",
    "    # breakdown the four factors that I plan to analyze. These are the formulas for those factors. \n",
    "    \n",
    "    four_factors_dataframe = test[['Player', 'eFG', 'TOV_per', 'ORB_per', 'FTr', 'Date']]\n",
    "    \n",
    "    uniq_id = str(year)+str(month)+str(day)+team\n",
    "    append_data = test[test['Player']==teams_scores['Team_Name'][0]]\n",
    "    append_data = append_data.append(test[test['Player']==teams_scores['Team_Name'][1]])\n",
    "    # add the team name to the output table - need to make sure this is done dynamically\n",
    "    \n",
    "    append_data['id_t'] = uniq_id\n",
    "    append_data['loc'] = team\n",
    "    # create a field to identify which team is the home team\n",
    "    \n",
    "    return append_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
